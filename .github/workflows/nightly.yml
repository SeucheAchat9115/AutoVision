# Nightly comprehensive testing
name: Nightly Tests

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"
  UV_VERSION: "0.4.0"

jobs:
  # Comprehensive test matrix
  test-matrix:
    name: Test Matrix
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11", "3.12"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv (Unix)
        if: runner.os != 'Windows'
        uses: astral-sh/setup-uv@v2
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install uv (Windows)
        if: runner.os == 'Windows'
        uses: astral-sh/setup-uv@v2
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Run comprehensive tests
        run: |
          uv run pytest tests/ --cov=autovision --cov-report=xml --tb=short

      - name: Upload coverage
        uses: codecov/codecov-action@v4
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          flags: nightly

  # Long-running and resource-intensive tests
  extended-tests:
    name: Extended Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v2
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Run slow tests
        run: |
          uv run pytest tests/ -m "slow" --cov=autovision --cov-report=xml

      - name: Run integration tests
        run: |
          uv run pytest tests/ -m "integration" --cov=autovision --cov-report=xml --cov-append

  # Security and dependency checks
  security-audit:
    name: Security Audit
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v2
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Run security checks
        run: |
          uv run bandit -r src/autovision -f json -o bandit-report.json
          uv run safety check --json --output safety-report.json

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json

  # Performance benchmarks
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v2
        with:
          version: ${{ env.UV_VERSION }}

      - name: Set up Python
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          uv sync --all-extras --dev

      - name: Install benchmark dependencies
        run: |
          uv add pytest-benchmark

      - name: Run performance tests
        run: |
          uv run pytest tests/ -m "not (slow or integration or gpu or youtube or model)" --benchmark-only --benchmark-json=benchmark-results.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json

  # Notify on failure
  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [test-matrix, extended-tests, security-audit, performance-tests]
    if: failure()

    steps:
      - name: Create issue on failure
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Nightly tests failed on ${new Date().toISOString().split('T')[0]}`,
              body: `The nightly test suite has failed. Please check the [workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId}) for details.`,
              labels: ['bug', 'nightly-failure', 'high-priority']
            })
